{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbe6a13-7e2f-4639-b9af-58bef0d9077e",
   "metadata": {},
   "source": [
    "# But : Créer un masque sans végétation avec une image infrarouge Pléiade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "086b554f-d051-4f64-9858-dd71898eda96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5522f9f-c28f-43d0-8812-b97f5d723e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install rasterio  -q -q -q\n",
    "! pip install geopandas -q -q -q\n",
    "! pip install matplotlib -q -q -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a7fd05-5b7f-4c68-8125-6aaa8c5d7ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyarrow\n",
    "!pip install opencv-python\n",
    "!pip install os-sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9fa2d88-9811-4141-95ac-9fa40385cf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from satellite_image import SatelliteImage\n",
    "from utils import *\n",
    "from plot_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127de47f-be5a-41c4-aae6-bc9b617fbffe",
   "metadata": {},
   "source": [
    "Lancer ça dans le terminal avant d'importer cv2 :\n",
    "* sudo apt-get update\n",
    "* sudo apt-get install ffmpeg libsm6 libxext6 -y\n",
    "* sudo apt-get install libgl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d341d1d8-c068-44fe-a520-e6d26b918c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import re\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e85ebe9-0368-4da8-ad77-96437e91ac81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e2ebdb-a1c7-4f1e-a0b8-714e40e8ced1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_storage_access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "237ab0fc-2df3-4c0c-9d4e-f42b1b009510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "environment = get_environment()\n",
    "\n",
    "root_path = get_root_path()\n",
    "bucket = environment[\"bucket\"]\n",
    "path_s3_cayenne_data = environment[\"sources\"][\"PLEIADES\"][2022][\"guyane\"]\n",
    "path_local_cayenne_data = os.path.join(root_path, environment[\"local-path\"][\"PLEIADES\"][2022][\"guyane\"])\n",
    "\n",
    "bucket = environment[\"bucket\"]\n",
    "\n",
    "path_s3_pleiades_data_2022_guyane = environment[\"sources\"][\"PLEIADES\"][2022][\"guyane\"]\n",
    "path_s3_bdtopo_data_2022_guyane = environment[\"sources\"][\"BDTOPO\"][2022][\"guyane\"]\n",
    "path_local_pleiades_data_2022_guyane = environment[\"local-path\"][\"PLEIADES\"][2022][\"guyane\"]\n",
    "path_local_bdtopo_data_2022_guyane = environment[\"local-path\"][\"BDTOPO\"][2022][\"guyane\"]\n",
    "\n",
    "path_s3_pleiades_data_2022_martinique = environment[\"sources\"][\"PLEIADES\"][2022][\"martinique\"]\n",
    "path_local_pleiades_data_2022_martinique = environment[\"local-path\"][\"PLEIADES\"][2022][\"martinique\"]\n",
    "\n",
    "path_s3_pleiades_data_2017_martinique = environment[\"sources\"][\"PLEIADES\"][2017][\"martinique\"]\n",
    "path_local_pleiades_data_2017_martinique = environment[\"local-path\"][\"PLEIADES\"][2017][\"martinique\"]\n",
    "\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f367887-1afb-45f1-a9d1-22509c9d6014",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chargement données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26aefa23-7dd1-42f7-ab78-c097e35e5559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DL PLEIADE guyane 2022\n",
    "fs.download(\n",
    "        rpath=f\"{bucket}/{path_s3_pleiades_data_2022_guyane}\",\n",
    "        lpath=f\"../{path_local_pleiades_data_2022_guyane}\",\n",
    "        recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "941f179e-4f19-4687-91e1-6e62da13269a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DL BDTOPO guyane 2022\n",
    "fs.download(\n",
    "        rpath=f\"{bucket}/{path_s3_bdtopo_data_2022_guyane}\",\n",
    "        lpath=f\"../{path_local_bdtopo_data_2022_guyane}\",\n",
    "        recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c357008-a7f2-4d97-b885-dfae1afa3a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DL PLEIADE martinique 2022\n",
    "fs.download(\n",
    "        rpath=f\"{bucket}/{path_s3_pleiades_data_2022_martinique}\",\n",
    "        lpath=f\"../{path_local_pleiades_data_2022_martinique}\",\n",
    "        recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3862fcf2-8e87-42f1-b8fe-02031942c708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DL PLEIADE martinique 2017\n",
    "fs.download(\n",
    "        rpath=f\"{bucket}/{path_s3_pleiades_data_2017_martinique}\",\n",
    "        lpath=f\"../{path_local_pleiades_data_2017_martinique}\",\n",
    "        recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5729069-8177-41dc-92cc-098c34c881e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image choisie\n",
    "filename = '../data/PLEIADES/2022/GUYANE/ORT_2022072050325085_0353_0545_U22N_16Bits.jp2'\n",
    "date = datetime.strptime(re.search(r'ORT_(\\d{8})', filename).group(1), '%Y%m%d')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "439fb99a-0819-4c80-9f87-426663e78782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = SatelliteImage.from_raster(\n",
    "        filename,\n",
    "        date = date, \n",
    "        n_bands = 4,\n",
    "        dep = \"973\"\n",
    "    )\n",
    "image.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2983a208-20ed-4c37-9d50-5f808a34e25d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.shape(image.array.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62205f2-b2c4-434a-b97e-0bb34083e9e7",
   "metadata": {},
   "source": [
    "## Idée globale : si le pixel est rouge, le changer en noir, le reste en blanc.\n",
    "Pour cela, il faut fixer des seuils : quel seuil sur l'infrarouge choisir, quels nuances de rouges colorier en noir ou en blanc ?\n",
    "Ici les pixels seront en décimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2886db7-ca00-40e5-9e68-8869d2c86562",
   "metadata": {},
   "source": [
    "## Méthode 1 : Seuillage sur l'infrarouge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4a4b0-9dfb-4411-b8f1-1d78a48a11b1",
   "metadata": {},
   "source": [
    "Voici l'image en couleurs puis avec l'infrarouge à la place du rouge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2315ccb6-f3b9-4e17-9723-62f456ff61ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image.plot([0,1,2])\n",
    "image.plot([3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea0eb748-fb6b-480d-904f-3bedbe7ac4a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on extrait l'array de l'image pour avoir les valeurs des pixels\n",
    "img = image.array\n",
    "\n",
    "#multiplication par 255 et convertion en uint8 pour avoir le bon format\n",
    "img = (img * 255).astype(np.uint8)\n",
    "\n",
    "img = img.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a748e-332a-48c3-9b1a-29ff2c984b49",
   "metadata": {},
   "source": [
    "On choisit ce seuil en testant plusieurs quantiles et en regardant le meilleur résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59a35960-5d99-499e-a4a5-4b089e03e150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.quantile(img[:,:,3],0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "957ad721-e506-42f0-af6d-430c03feb1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on parcours tous les pixels et on les modifie en fonction du seuil\n",
    "for row in range(img.shape[0]):\n",
    "    for col in range(img.shape[1]):\n",
    "        i = img[row,col,3]\n",
    "        if i > 139: #médiane\n",
    "            img[row, col] = np.array([0, 0, 0,0]) # blanc\n",
    "\n",
    "        else : \n",
    "            img[row, col] = np.array([255,255,255,255]) # noir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2e465ea-5fc7-44ef-b61b-c850acfe98c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = img.transpose()\n",
    "\n",
    "#On veut le bon format\n",
    "img = (img/255).astype(np.float64)\n",
    "\n",
    "image.array = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a5a0734-e2b8-448d-b679-aee74b814155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image.plot([0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56130fb-8d84-44d6-a09d-4813381d639f",
   "metadata": {},
   "source": [
    "## Méthode 2 : transformation de l'image infrarouge en image RGB en remplacant le rouge par l'infrarouge puis seuillage sur les 3 couleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85761931-78c8-4fd8-b7b9-a97edfc4f6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on recharge l'image originale\n",
    "image = SatelliteImage.from_raster(\n",
    "        filename,\n",
    "        date = date, \n",
    "        n_bands = 4,\n",
    "        dep = \"973\"\n",
    "    )\n",
    "image.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9247210c-f0f3-44ae-903d-2e57a464419b",
   "metadata": {
    "tags": []
   },
   "source": [
    "On va refaire le même algorithme, sauf qu'on va changer les seuils sur les pixels RGB à la place de seulement infrarouge comme précedemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff8e4961-2fc8-4e9e-a4a6-3cf9e7b99eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = image.array\n",
    "\n",
    "img = (img * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "img = img.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe521002-f263-4043-9c84-e36b770c4e45",
   "metadata": {},
   "source": [
    "* Etape 1 : Pour que le pixel soit une nuance de rouge, il faut d'abord vérifier si les valeurs verte et bleue sont proches.\n",
    "* Etape 2 : On décide que les nuances de rouge très claires correspondent à des toits de bâtiments.\n",
    "* Etape 3 : On fixe le seuil de la valeur rouge à 110 et la valeur de rouge avec une autre couleur doit être supérieure à 20 minimum.\n",
    "* Etape 4 : Si le pixel ne vérifie aucune des étapes précédentes, alors il est colorié automatiquement en blanc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f48575-3573-45e1-a227-946c7ec8f6bc",
   "metadata": {},
   "source": [
    "Pour fixer ce seuil, des tests visuels ont été effectués et on a utilisé ce site https://htmlcolorcodes.com/fr/selecteur-de-couleur/ pour comprendre comment fonctionnent les nuances de rouge sur des pixels en décimal (et ce site pour comprendre les pixels en décimal en général http://www.proftnj.com/RGB3.htm).\n",
    "L'algorithme qui suit met quelques secondes à tourner, il sera long s'il est appliqué sur l'ensemble des images de la base de données.\n",
    "Pour mieux réussir à faire ce seuillage en étape 3, on devrait créer une fonction racine carré et prendre toutes les valeurs au dessus de la courbe.\n",
    "Cette fonction est difficile à déterminer... Cependant, on peut la faire uniquement avec deux paramètres : la valeur du rouge et la valeur minimale entre le bleu et le vert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "900a6a7d-ca06-41d6-b417-2a4b737e6699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# On va parcourir tous les pixels de l'image\n",
    "for row in range(img.shape[0]):\n",
    "    for col in range(img.shape[1]):\n",
    "        b = img[row,col, 1]\n",
    "        g = img[row,col, 2]\n",
    "        r = img[row,col, 3]\n",
    "        mini = min(b,g)\n",
    "        maxi = max(b,g)\n",
    "        \n",
    "        if maxi-mini <= 20 : #étape 1\n",
    "            \n",
    "            if r > 200 and mini >= 110 and r>= (20+mini): #étape 2\n",
    "                img[row, col] = [255,255,255,255] # blanc\n",
    "            elif  r>= (20+mini) and r >= 110: #étape 3\n",
    "                img[row, col] = [0,0,0,0] #noir\n",
    "            else : #étape 4\n",
    "                img[row, col] = [255,255,255,255] # blanc\n",
    "\n",
    "        else : #étape 4\n",
    "            img[row, col] = [255,255,255,255] # blanc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d3a6715-c56c-4e4b-b1ed-9866ae9d1a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = img.transpose()\n",
    "\n",
    "#On veut le bon format\n",
    "img = (img/255).astype(np.float64)\n",
    "\n",
    "image.array = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d0ed163-a6c8-499b-a4c1-1065448baf9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image.plot([0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a19b71e-8936-4c0d-b210-bd5fb3eb7f68",
   "metadata": {},
   "source": [
    "Ici, la 2ème méthode est plus effective. En effet, on prend en compte que certains toits vont refleter les ondes infrarouges et donc sortir comme rouge clair une fois l'image convertie en RGB. Cependant, la méthode du seuillage sur l'infrarouge reste la plus simple : méthode concise et temps de calcul plus rapide. Les résultats semblent globalement bon dans les deux cas. A voir quelle méthode se généralise le mieux..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaeda3c-2506-4fde-b2d9-c00c6eacba0d",
   "metadata": {},
   "source": [
    "## Essai au cas où : Détection de contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "845b651a-8969-4dc6-930f-b571282ff135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#On récupère l'image au format RGB puis on la transforme en png pour pouvoir l'utiliser avec OpenCV\n",
    "img = image.array\n",
    "\n",
    "img = img[[0,1,2],:, :]\n",
    "\n",
    "img = (img*255).astype(np.uint8)\n",
    "\n",
    "#convertir l'array en image PIL pour ensuite l'avoir en png\n",
    "img = im.fromarray(img.transpose(1, 2, 0).astype('uint8'), 'RGB')\n",
    "\n",
    "#enregistrer l'image en tant que fichier PNG pour pouvoir utiliser OpenCV\n",
    "img.save('masque.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fca216-a29f-4097-8019-25aa552a2a37",
   "metadata": {},
   "source": [
    "Afin de ne pas faire crasher le kernel, nous allons préalablement créer des fonctions d'affichage des images avec OpenCV (la fonction de base cv2.imshow() fait crasher le kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb22ec9b-09dd-41b9-a12a-fea8d182ba90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#images en nuances de gris\n",
    "def cv2_imshow(a, **kwargs):\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    if a.ndim == 3:\n",
    "        if a.shape[2] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_RGBA2BGRA)\n",
    "        else:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return plt.imshow(a, **kwargs, cmap= \"gray\")\n",
    "\n",
    "#images en couleurs\n",
    "def cv2_imshow2(a, **kwargs):\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    if a.ndim == 3:\n",
    "        if a.shape[2] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_RGBA2BGRA)\n",
    "        else:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return plt.imshow(a, **kwargs, cmap= \"brg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91b2faff-f175-44eb-b80d-742c1dcfd130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on lit l'image avec OpenCV\n",
    "img = cv2.imread('masque.png')\n",
    "\n",
    "#avoir le bon format : ici on veut RGB (la transposée nous a fait passer en BGR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 100, 200)\n",
    "  \n",
    "# Finding Contours\n",
    "# Use a copy of the image e.g. edged.copy()\n",
    "# since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, \n",
    "    cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "img_contours = cv2.drawContours(img, contours, -1, (0, 255, 0), 5)\n",
    "cv2_imshow2(img_contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae16a6-3da0-4149-8f21-5623a49e30ea",
   "metadata": {},
   "source": [
    "Ce qui serait intéressant de faire, c'est de prendre en entrée des images où on sait qu'il y a des bidonvilles, on enlève la végétation avec la méthode 2 mais on garde les couleurs de base sur les pixels sans végétation et ensuite on classifie ces pixels avec un algo des k-means. Comme ça, on peut faire plusieurs classes d'objets : routes, gros bâtiments, maisons, bidonvilles. On determine à la main quelle classe correspond à quel type d'objets. Puis on fait un masque binaire : en blanc les pixels dans la classe bidonville, en noir le reste. Cela pourrait nous aider à constituer des données d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f795384-7341-4e32-a22c-bcbf9aec651c",
   "metadata": {},
   "source": [
    "## Maintenant, il serait intéressant de comparer deux images d'un même lieu sur deux périodes données où on sait qu'il y a eu une création/destruction de bâtiment entre temps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d768b0-ca86-455e-b1f6-3fece9addbb9",
   "metadata": {},
   "source": [
    "## Idée globale : \n",
    "Trouver un lieu où il y a eu une construction/destruction de bâtiments entre deux millésimes et appliquer la méthode pour obtenir un masque sur les deux images infrarouge du même lieu à deux période données. Ensuite superposer ces deux masques et faire des différences de pixels : les différences sortiront en blanc et les similarités en noir. Pour finir, on veut lisser l'image, c'est à dire trouver un seuil à partir duquel on considère qu l'amas de pixels représente un changement significatif. \n",
    "\n",
    "La première difficulté ici est de trouver deux images différentes d'un même lieu. On va parcourir les données pour savoir si c'est possible ou si c'est irréalisable sans faire de transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1e29d62-55e4-4679-aaaa-30ad4e17eb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image 1\n",
    "filename_1 = '../data/PLEIADES/2022/MARTINIQUE/ORT_2022_0713_1607_U20N_8Bits.jp2'\n",
    "date_1 = date.fromisoformat('2022-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c90eddea-d695-4c4e-b118-783580e1c6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_1 = SatelliteImage.from_raster(\n",
    "        filename_1,\n",
    "        date = date_1, \n",
    "        n_bands = 3,\n",
    "        dep = \"972\"\n",
    "    )\n",
    "image_1.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3436f51-7b12-47fd-8d74-bd43e12877c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_1.plot([0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c5e47-bd2d-440d-b220-837fba64fcce",
   "metadata": {
    "tags": []
   },
   "source": [
    "On créé des fonctions crs_to_gps() et gps_to_crs() pour retrouver l'image sur google maps grâce à ses coordonnées crs transformées en gps et inversement, pour retrouver un point gps repéré sur Google Maps et le situer sur les images de la base de données grâce à ses données crs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69f3a191-3d82-47c2-8964-0f83bd5aede1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pyproj\n",
    "\n",
    "def crs_to_gps(satellite_image) :\n",
    "    \n",
    "    #avoir les coordonnées du boundingbox\n",
    "    boundingbox = list(satellite_image.bounds)\n",
    "    \n",
    "    #avoir le crs\n",
    "    str_crs = str(satellite_image.crs)\n",
    "\n",
    "    # Rechercher la séquence d'entiers dans la chaîne de caractères\n",
    "    crs = re.findall(r'\\d+', str_crs)\n",
    "    crs = int(crs[0])\n",
    "    \n",
    "    #convertir en coordonnées gps\n",
    "    src_proj = pyproj.Proj(crs)\n",
    "    dest_proj = pyproj.Proj(proj='latlong')\n",
    "    \n",
    "    # Convertir les coordonnées dans le système de coordonnées de départ en coordonnées dans le système de coordonnées de destination (GPS)\n",
    "    #on prend la coordonnées top-left arbitrairement\n",
    "    x = boundingbox[0] #left\n",
    "    y = boundingbox[3] #top\n",
    "    lon, lat = pyproj.transform(src_proj, dest_proj, x, y, always_xy=True)\n",
    "    \n",
    "    # Retourner les coordonnées GPS (latitude, longitude)\n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d5b636a-9ac2-48eb-bd1d-05e8f1ea3f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crs_to_gps(image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89521f-ebc0-4e88-ba3f-a31adc5a1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gps_to_crs(lat,lon,crs) :\n",
    "    \n",
    "    # Définir les systèmes de coordonnées de départ et d'arrivée\n",
    "    src_proj = pyproj.Proj(proj='latlong')\n",
    "    dest_proj = pyproj.Proj(crs)\n",
    "    \n",
    "    # Convertir les coordonnées GPS en coordonnées dans le système de coordonnées de destination (CRS)\n",
    "    x, y = pyproj.transform(src_proj, dest_proj, lon, lat)\n",
    "    \n",
    "    # Retourner les coordonnées dans le CRS spécifié\n",
    "    return x, y\n",
    "\n",
    "#ca serait bien de faire une fonction qui cherche dans l'ensemble des données l'image qui contiendra cette coordonées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7edfb-6bce-4aca-8c4e-6af22aa0c476",
   "metadata": {},
   "source": [
    "(14.618229, -61.102878) correspond à des coordonnées gps d'un quartier avec des bâtiments à Schoelcher.\n",
    "Essayons de retrouver l'image qui le contient.\n",
    "\n",
    "Crééons une fonction qui réunie toutes les images de la base de données de la Martinique 2022, qui affiche l'ensemble de la Martinique et qui peut situer une coordonnées gps/crs dans l'ensemble et nous dire quelle image est concernée."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
