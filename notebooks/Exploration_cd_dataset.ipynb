{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install rasterio\n",
    "! pip install geopandas \n",
    "! pip instalml pyarrow\n",
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from satellite_image import SatelliteImage\n",
    "from utils import *\n",
    "from plot_utils import *\n",
    "import yaml\n",
    "import re\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_storage_access()\n",
    "environment = get_environment()\n",
    "root_path = get_root_path()\n",
    "bucket = environment[\"bucket\"]\n",
    "path_s3_s2looking = environment[\"sources\"][\"PAPERS\"][\"S2Looking\"]\n",
    "path_local_s2looking = environment[\"local-path\"][\"PAPERS\"]\n",
    "\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_local_s2looking\n",
    "#root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs.download(\n",
    "        rpath=f\"{bucket}/{path_s3_s2looking}\",\n",
    "        lpath=f\"../{path_local_s2looking}\",\n",
    "        recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(f\"../{path_local_s2looking}/S2Looking.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(f\"../{path_local_s2looking}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go Pytorch Lightning ! \n",
    "Le but  que je me fixe ici est de réutiliser la logique de Tom jusqU40 ENTRAÏNEMENT AVE CpYTRCH lIGHTNING\n",
    "Ici je vais sanctuariser l'approche par chemin de fichier où je charge une image et je sélectionne une seule aléatoirement dans l'ensemble ?\n",
    "METTRE EN OPALCE DES METRIQUE SPOUR mlflow t& score etc;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = f\"../{path_local_s2looking}/S2Looking/train/\"\n",
    "list_name = sorted(os.listdir(os.path.join(train_path,\"Image1\")))\n",
    "list_path_image1 =  [ os.path.join(train_path,\"Image1/\")+ name for name  in list_name]\n",
    "list_path_image2 =  [ os.path.join(train_path,\"Image2/\")+ name for name  in list_name]\n",
    "list_path_label =  [ os.path.join(train_path,\"label/\")+ name for name  in list_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import change_detection_triplet\n",
    "idx = 35\n",
    "pthimg1 = list_path_image1[idx]\n",
    "pthimg2 = list_path_image2[idx]\n",
    "pthlabel = list_path_label[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from change_detection_triplet import ChangedetectionTripletS2Looking\n",
    "cdtriplet = ChangedetectionTripletS2Looking(pthimg1,pthimg2,pthlabel)\n",
    "cdtriplet.random_crop(512)\n",
    "cdtriplet.plot()\n",
    "\n",
    "#.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fonction de découpage aléatoire dans utils d'une image Pil (taille 250) ? regarder le crop aléatoire de l'autre notebook, l'intégrer dans la classe Dataset.\n",
    "- Entraîner le Unet++ ?\n",
    "- créer cette classe plutôt pour l'évaluation quali du réseau  \n",
    "- créer une classe triplet Satellites Images \n",
    "- (finalement ces classes sont plus utiles pour représenter et garder l'info géo ?)\n",
    "- fontion  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une classe Data set pour chopper les images\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch\n",
    "from typing import List, Optional, Union\n",
    "from albumentations import Compose\n",
    "\n",
    "class ChangeDetectionS2LookingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        list_paths_image1: List,\n",
    "        list_paths_image2: List,\n",
    "        list_paths_labels: List,\n",
    "        transforms: Optional[Compose] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "\n",
    "        Args:\n",
    "            list_paths_image1 (List): list of path of the before state pictures\n",
    "            list_paths_image2 (List): list of paths containing  the \"after\" state pictures\n",
    "            list_paths_labels (List): list of paths containing the labeled differences (mostly segmentation masque showing the differencer between image 1 and image 2) \n",
    "        \"\"\"\n",
    "        self.list_paths_image1 = list_paths_image1\n",
    "        self.list_paths_image2 = list_paths_image2\n",
    "        self.list_paths_labels = list_paths_labels    \n",
    "        self.transforms = transforms\n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            idx (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        pathim1 = self.list_paths_image1[idx]\n",
    "        pathim2 = self.list_paths_image2[idx]\n",
    "        pathlabel = self.list_paths_labels[idx]\n",
    "        \n",
    "        cdtriplet = ChangedetectionTripletS2Looking(pthimg1,pthimg2,pthlabel)\n",
    "        cdtriplet.random_crop(256)\n",
    "            \n",
    "        img1 = np.transpose(np.array(cdtriplet.image1),(2,0,1))\n",
    "        img2 = np.transpose(np.array(cdtriplet.image2),(2,0,1))\n",
    "        \n",
    "        img_double =np.concatenate([img1,img2],axis = 0).squeeze()\n",
    "        \n",
    "        label = np.array(cdtriplet.label)\n",
    "        label[label!=0] = 1\n",
    "        \n",
    "        sample = {\"image\": img_double, \"mask\": label}\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image=img_double, mask=label)\n",
    "            \n",
    "        img_double = sample[\"image\"]\n",
    "        label = sample[\"mask\"]\n",
    "        \n",
    "        return img_double, label, cdtriplet # un peu loulourd de garder le triplet, mais ça pemet de plotter quand on veut\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.list_paths_image1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ds = ChangeDetectionS2LookingDataset(list_path_image1,list_path_image2,list_path_label)\n",
    "iterateur = iter(ds)\n",
    "\n",
    "img, label, cd_triplet = next(iterateur)\n",
    "print(img.shape)\n",
    "cd_triplet.plot()\n",
    "\n",
    "# je vais mettre un Unet par dessus pour l'instant et m'intéresser  au pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Peut on généraliser un peu l'utilisation des Dataset dans le S2 Looking etc.. faire une fionctuion qui prend en entrée un dataset de Segmentatione tyC.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "class S2LookingDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    Pytorch Lightning Data Module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data: List[str],\n",
    "        valid_data: List[str],\n",
    "        test_data:  List[str],\n",
    "        transforms_preprocessing: Optional[Compose] = None,\n",
    "        transforms_augmentation: Optional[Compose] = None,\n",
    "        batch_size: int = 20,\n",
    "        num_workers: int = 4\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Data Module constructor.\n",
    "\n",
    "        Args:\n",
    "            train_data (List): List of training (and validation) instances\n",
    "            test_data (List): List of test instances\n",
    "            transforms_preprocessing (Optional[Compose]): Compose object\n",
    "                from albumentations applied on validation and test datasets.\n",
    "            transforms_augmentation (Optional[Compose]): Compose object\n",
    "                from albumentations applied on training dataset.\n",
    "            batch_size (int): Batch size.\n",
    "            num_workers (int): Number of workers to process data.\n",
    "            bands_indices (List): List of indices of bands to plot.\n",
    "                The indices should be integers between 0 and the\n",
    "                number of bands - 1.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.train_data = train_data # list containing image1 path, imaghe 2 paths and label paths\n",
    "        self.valid_data = valid_data\n",
    "        self.test_data = test_data\n",
    "        self.transforms_preprocessing = transforms_preprocessing\n",
    "        self.transforms_augmentation = transforms_augmentation\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self, stage: str = None) -> None:\n",
    "        \"\"\"\n",
    "        Start training, validation and test datasets.\n",
    "\n",
    "        Args:\n",
    "            stage (Optional[str]): Used to separate setup logic\n",
    "                for trainer.fit and trainer.test.\n",
    "        \"\"\"\n",
    "        n_samples = len(self.train_data[0])\n",
    "        \n",
    "        self.dataset_train = ChangeDetectionS2LookingDataset(\n",
    "            self.train_data[0],\n",
    "            self.train_data[1],\n",
    "            self.train_data[2]\n",
    "        )\n",
    "            \n",
    "        self.dataset_val = ChangeDetectionS2LookingDataset(\n",
    "            self.valid_data[0],\n",
    "            self.valid_data[1],\n",
    "            self.valid_data[2]\n",
    "        )\n",
    "        \n",
    "        self.dataset_test = ChangeDetectionS2LookingDataset(\n",
    "            self.test_data[0],\n",
    "            self.test_data[1],\n",
    "            self.test_data[2]\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self, *args, **kwargs) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Create Dataloader.\n",
    "        Returns: DataLoader\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.dataset_train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self, *args, **kwargs) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Create Dataloader.\n",
    "        Returns: DataLoader\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.dataset_val,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self, *args, **kwargs) -> DataLoader:\n",
    "        \"\"\"Create Dataloader.\n",
    "        Returns: DataLoader\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.dataset_test,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le modèle et l'Opti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, Union\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "class DeepLabv3Module(nn.Module):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.segmentation.deeplabv3_resnet101(\n",
    "            weights=\"DeepLabV3_ResNet101_Weights.DEFAULT\"\n",
    "        )\n",
    "        # 1 classe !\n",
    "        self.model.classifier[4] = nn.Conv2d(\n",
    "            256, 2, kernel_size=(1, 1), stride=(1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class DeepLabv3LitModule(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Pytorch Lightning Module for DeepLabv3.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: DeepLabv3Module,\n",
    "        optimizer: Union[optim.SGD, optim.Adam],\n",
    "        optimizer_params: Dict,\n",
    "        scheduler: Union[\n",
    "            optim.lr_scheduler.OneCycleLR, optim.lr_scheduler.ReduceLROnPlateau\n",
    "        ],\n",
    "        scheduler_params: Dict,\n",
    "        scheduler_interval: str,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize TableNet Module.\n",
    "        Args:\n",
    "            model\n",
    "            optimizer\n",
    "            optimizer_params\n",
    "            scheduler\n",
    "            scheduler_params\n",
    "            scheduler_interval\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer_params = optimizer_params\n",
    "        self.scheduler = scheduler\n",
    "        self.scheduler_params = scheduler_params\n",
    "        self.scheduler_interval = scheduler_interval\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Perform forward-pass.\n",
    "        Args:\n",
    "            batch (tensor): Batch of images to perform forward-pass.\n",
    "        Returns (Tuple[tensor, tensor]): Table, Column prediction.\n",
    "        \"\"\"\n",
    "        return self.model(batch)[\"out\"]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training step.\n",
    "        Args:\n",
    "            batch (List[Tensor]): Data for training.\n",
    "            batch_idx (int): batch index.\n",
    "        Returns: Tensor\n",
    "        \"\"\"\n",
    "        samples, labels = batch\n",
    "\n",
    "        # TODO: Conversion to do before\n",
    "        labels = labels.type(torch.LongTensor).to(self.device)\n",
    "        output = self.forward(samples)[\"out\"]\n",
    "\n",
    "        loss = self.loss(output, labels)\n",
    "        self.log(\"loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step.\n",
    "        Args:\n",
    "            batch (List[Tensor]): Data for training.\n",
    "            batch_idx (int): batch index.\n",
    "        Returns: Tensor\n",
    "        \"\"\"\n",
    "        samples, labels = batch\n",
    "\n",
    "        labels = labels.type(torch.LongTensor).to(self.device)\n",
    "        output = self.forward(samples)\n",
    "\n",
    "        loss = self.loss(output, labels)\n",
    "        self.log(\"validation_loss\", loss, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Test step.\n",
    "        Args:\n",
    "            batch (List[Tensor]): Data for training.\n",
    "            batch_idx (int): batch index.\n",
    "        Returns: Tensor\n",
    "        \"\"\"\n",
    "        samples, labels = batch\n",
    "        labels = labels.type(torch.LongTensor).to(self.device)\n",
    "        output = self.forward(samples)[\"out\"]\n",
    "\n",
    "        loss = self.loss(output, labels)\n",
    "        self.log(\"test_loss\", loss, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configure optimizer for pytorch lighting.\n",
    "        Returns: optimizer and scheduler for pytorch lighting.\n",
    "        \"\"\"\n",
    "        optimizer = self.optimizer(self.parameters(), **self.optimizer_params)\n",
    "        scheduler = self.scheduler(optimizer, **self.scheduler_params)\n",
    "        scheduler = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"monitor\": \"validation_loss\",\n",
    "            \"interval\": self.scheduler_interval,\n",
    "        }\n",
    "\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import albumentations as album\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Loading images\n",
    "    # DataModule definition\n",
    "    # Some additional normalization is done here\n",
    "image_size = (256, 256)\n",
    "transforms_augmentation = album.Compose(\n",
    "        [\n",
    "            album.Resize(300, 300, always_apply=True),\n",
    "            album.RandomResizedCrop(\n",
    "                *image_size, scale=(0.7, 1.0), ratio=(0.7, 1)\n",
    "            ),\n",
    "            album.HorizontalFlip(),\n",
    "            album.VerticalFlip(),\n",
    "            album.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "transforms_preprocessing = album.Compose(\n",
    "        [\n",
    "            album.Resize(*image_size, always_apply=True),\n",
    "            album.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    ")\n",
    "\n",
    "\n",
    "train_path = f\"../{path_local_s2looking}/S2Looking/train/\"\n",
    "list_name = sorted(os.listdir(os.path.join(train_path,\"Image1\")))\n",
    "train_path_image1 =  [ os.path.join(train_path,\"Image1/\")+ name for name  in list_name]\n",
    "train_path_image2 =  [ os.path.join(train_path,\"Image2/\")+ name for name  in list_name]\n",
    "train_path_label =  [ os.path.join(train_path,\"label/\")+ name for name  in list_name]\n",
    "\n",
    "\n",
    "valid_path = f\"../{path_local_s2looking}/S2Looking/val/\"\n",
    "list_name = sorted(os.listdir(os.path.join(valid_path,\"Image1\")))\n",
    "valid_path_image1 =  [ os.path.join(valid_path,\"Image1/\")+ name for name  in list_name]\n",
    "valid_path_image2 =  [ os.path.join(valid_path,\"Image2/\")+ name for name  in list_name]\n",
    "valid_path_label =  [ os.path.join(valid_path,\"label/\")+ name for name  in list_name]\n",
    "\n",
    "test_path = f\"../{path_local_s2looking}/S2Looking/test/\"\n",
    "list_name = sorted(os.listdir(os.path.join(test_path,\"Image1\")))\n",
    "test_path_image1 =  [ os.path.join(test_path,\"Image1/\")+ name for name  in list_name]\n",
    "test_path_image2 =  [ os.path.join(test_path,\"Image2/\")+ name for name  in list_name]\n",
    "test_path_label =  [ os.path.join(test_path,\"label/\")+ name for name  in list_name]\n",
    "\n",
    "data_module = S2LookingDataModule(\n",
    "    train_data=[train_path_image1, train_path_image2, train_path_label],\n",
    "    valid_data =[valid_path_image1, valid_path_image2, valid_path_label],\n",
    "    test_data =[test_path_image1, test_path_image2, test_path_label],\n",
    "    transforms_augmentation=transforms_augmentation,\n",
    "    transforms_preprocessing=transforms_preprocessing,\n",
    "    num_workers=56,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "optimizer = torch.optim.SGD\n",
    "optimizer_params = {\"lr\": 0.0001, \"momentum\": 0.9}\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "scheduler_params = {}\n",
    "scheduler_interval = \"epoch\"\n",
    "\n",
    "model = DeepLabv3Module()\n",
    "lightning_module = DeepLabv3LitModule(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_params=optimizer_params,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_params=scheduler_params,\n",
    "    scheduler_interval=scheduler_interval,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"validation_loss\", save_top_k=1, save_last=True, mode=\"min\"\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"validation_loss\", mode=\"min\", patience=3\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "gpus = 1\n",
    "strategy = \"ddp\" if gpus > 1 else None\n",
    "strategy =\"auto\"\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[lr_monitor, checkpoint_callback, early_stop_callback],\n",
    "    max_epochs=2,\n",
    "   # gpus=gpus,\n",
    "    num_sanity_val_steps=2,\n",
    "    strategy=strategy,\n",
    ")\n",
    "trainer.fit(lightning_module, datamodule=data_module)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
