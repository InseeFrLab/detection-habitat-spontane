{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e064d8b4-2af2-4263-800f-713875386be0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fonction to Raster\n",
    "Prend en entrée une Satellite Image, un dossier et un nom et la sauve en JP2 dans le dossier considéré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b683696-509c-466e-bdee-73d3aba6e3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install pyarrow -q -q -q \n",
    "! pip install rasterio -q -q -q \n",
    "! pip install geopandas -q -q -q\n",
    "! pip install matplotlib -q -q -q\n",
    "! pip install albumentations -q -q -q\n",
    "! pip install pytorch_lightning -q -q -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "524c5b49-9f48-4092-a43a-ad47710a6f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from satellite_image import SatelliteImage\n",
    "from utils.utils import *\n",
    "from utils.plot_utils import *\n",
    "\n",
    "import yaml\n",
    "import re\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "from PIL import Image as im\n",
    "\n",
    "from datetime import date\n",
    "import re\n",
    "import pyproj\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from labeler import RILLabeler\n",
    "from filter import is_too_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "45654cf2-d2ef-4ae5-bf12-5a008ff640c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_path = get_root_path()\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27d90c35-321b-44d0-a9ea-a0b8084ade17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_storage_access()\n",
    "environment = get_environment()\n",
    "\n",
    "root_path = get_root_path()\n",
    "bucket = environment[\"bucket\"]\n",
    "path_s3_cayenne_data = environment[\"sources\"][\"PLEIADES\"][2022][\"guyane\"]\n",
    "path_local_cayenne_data = os.path.join(root_path, environment[\"local-path\"][\"PLEIADES\"][2022][\"guyane\"])\n",
    "\n",
    "path_s3_pleiades_data_2022_martinique = environment[\"sources\"][\"PLEIADES\"][2022][\"martinique\"]\n",
    "path_local_pleiades_data_2022_martinique = environment[\"local-path\"][\"PLEIADES\"][2022][\"martinique\"]\n",
    "\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c92228ba-5dd3-4755-83e5-afa24a5b7e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs.download(\n",
    "        rpath=f\"{bucket}/{path_s3_cayenne_data}\",\n",
    "        lpath=f\"{path_local_cayenne_data}\",\n",
    "        recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dab4c183-2d06-4364-89da-94633ca0757a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_raster(satellite_image,directory_name,file_name):\n",
    "    \"\"\"\n",
    "    save a SatelliteImage Object into a raster file (.tif)\n",
    "\n",
    "    Args:\n",
    "        satellite_image: a SatelliteImage object representing the input image to be saved as a raster file.\n",
    "        directory_name: a string representing the name of the directory where the output file should be saved.\n",
    "        file_name: a string representing the name of the output file.\n",
    "    \"\"\"\n",
    "\n",
    "    data = satellite_image.array\n",
    "    crs  = satellite_image.crs\n",
    "    transform = satellite_image.transform\n",
    "    n_bands = satellite_image.n_bands\n",
    "\n",
    "    metadata = {\n",
    "        'dtype': data.dtype,\n",
    "        'count': n_bands,\n",
    "        'width': data.shape[2],\n",
    "        'height': data.shape[1],\n",
    "        'crs': crs,\n",
    "        'transform': transform\n",
    "    }\n",
    "    \n",
    "    #print(os.path.exists(directory_name))\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "\n",
    "    # Save the array as a raster file in jp2 format\n",
    "    with rasterio.open(directory_name + \"/\" + file_name, 'w', **metadata) as dst:\n",
    "        dst.write(data, indexes = np.arange(n_bands)+1)\n",
    "\n",
    "\n",
    "def write_splitted_images_masks(file_path,output_directory_name,labeler,tile_size,n_bands, dep):\n",
    "    \n",
    "    \"\"\"\n",
    "    write the couple images mask into a specific folder\n",
    "\n",
    "    Args:\n",
    "        file_path: a string representing the path to the directory containing the input image files.\n",
    "        output_directory_name: a string representing the name of the output directory where the split images and masks should be saved.\n",
    "        labeler: a Labeler object representing the labeler used to create segmentation labels.\n",
    "        tile_size: an integer representing the size of the tiles to split the input image into.\n",
    "        n_bands: an integer representing the number of bands in the input image.\n",
    "        dep: a string representing the department of the input image, or None if not applicable.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_images_path  = output_directory_name + \"/images\"\n",
    "    output_masks_path  = output_directory_name + \"/labels\"\n",
    "    \n",
    "    if not os.path.exists(output_masks_path):\n",
    "        os.makedirs(output_masks_path)\n",
    "        \n",
    "    list_name = os.listdir(file_path)\n",
    "    list_path = [file_path + \"/\" + name for name in list_name]\n",
    "    \n",
    "    for path, file_name in zip(list_path,tqdm(list_name)): # tqdm ici \n",
    "\n",
    "        big_satellite_image = SatelliteImage.from_raster(\n",
    "            file_path = path,\n",
    "            dep = None,\n",
    "            date = None,\n",
    "            n_bands= 3\n",
    "        )\n",
    "\n",
    "        list_satellite_image = big_satellite_image.split(tile_size)\n",
    "        list_satellite_image = [im for im in list_satellite_image if not is_too_black(im)]\n",
    "        # mettre le filtre is too black ici !!!\n",
    "        for i, satellite_image in enumerate(list_satellite_image):\n",
    "                \n",
    "                file_name_i = file_name.split(\".\")[0]+\"_\"+str(i)\n",
    "                to_raster(satellite_image,output_images_path,file_name_i + \".tif\")\n",
    "                \n",
    "                # mask\n",
    "                mask = labeler.create_segmentation_label(satellite_image) \n",
    "                np.save(output_masks_path+\"/\"+file_name_i+\".npy\",mask) # save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b673b6-83d8-4a97-9c25-9af4458d077c",
   "metadata": {},
   "source": [
    "### Test sur une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9bcba4f9-9ffb-49c6-91b7-4bf83514ad67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "satellite_image = SatelliteImage.from_raster(\n",
    "        file_path = f\"{path_local_cayenne_data}\"+ \"/ORT_2022072050325085_0352_0545_U22N_16Bits.jp2\",\n",
    "        dep = None,\n",
    "        date = None,\n",
    "        n_bands= 4)\n",
    "\n",
    "print(satellite_image.array.shape)\n",
    "i = 2\n",
    "directory_name = \"../splitted_data\"\n",
    "file_name = \"ORT_2022072050325085_0352_0545_U22N_16Bits\"+\"_\"+str(i)+\".tif\"\n",
    "\n",
    "to_raster(satellite_image,directory_name,file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8440798-f11c-4261-a8e0-ad2c17cbaf58",
   "metadata": {},
   "source": [
    "## Test sur l'ensemble des images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e4631-0148-411f-a1b6-8b80f013458b",
   "metadata": {},
   "source": [
    "- je prends un répertoire en entrée Par exemple Guyane et je lis je split et réécris les images en taille 250\n",
    "- compter le nombre d'images à traiter et le nombre d'images à l'arrivée.\n",
    "- Si plusieurs années dispo généraliser le labeller "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8840269a-d846-4962-a4d4-79e8eb0321c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# params \n",
    "file_path = f\"{path_local_cayenne_data}\"\n",
    "tile_size = 250\n",
    "n_bands = 3\n",
    "dep =\"973\"\n",
    "filename = os.listdir(file_path)[0]\n",
    "date = datetime.strptime(re.search(r'ORT_(\\d{8})', filename).group(1), '%Y%m%d') \n",
    "labeler = RILLabeler(date, dep = dep, buffer_size = 10) \n",
    "output_directory_name = \"../splitted_data\"\n",
    "\n",
    "write_splitted_images_masks(file_path,output_directory_name,labeler,tile_size,n_bands,dep)\n",
    "\n",
    "# 1 min pour 250 -> 4min pour 1000, ça se tente un peu lionguet mais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "12338605-a045-40f0-9261-6988618b22b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(os.listdir(output_directory_name+\"/labels\"))\n",
    "len(os.listdir(output_directory_name+\"/images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea14795-2b15-405e-9996-c6b41776baae",
   "metadata": {},
   "source": [
    "- a priori si je connais le file path : je connais la date et je connais le labeller => créer labeller en amont ?\n",
    "- On crée un labeller par date et par territoire concerné \n",
    "- On créé les masques et on les sauvegarde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600a146c-38b0-4d79-8d61-9300000ddc51",
   "metadata": {},
   "source": [
    "### Les filtres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790c19be-f13b-4b60-b8ca-083f8801d041",
   "metadata": {},
   "source": [
    "- Pas de point RIL ... -> out\n",
    "- trop de nuage  -> out \n",
    "- trop de noir -> out (effets de bord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dbdcb7a1-a998-4da7-a1c5-81f383803777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be9a045d-bfa4-498e-b36e-edf16850fc97",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Réadaptation de la classe DeeplaV3module pour la rendre agnostique  au dataset etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4655d7f-e82e-442b-b0bb-72d860961750",
   "metadata": {},
   "source": [
    "- modifier les codes de tom pour faire en sorte que les lightning module soient plus résiliants aux modèles ?\n",
    "- vérifier que le code de Tom marche toujours malgré les modifs \n",
    "- normaliser les sortie de data set , image mask pour que ça marche bien aussi \n",
    "- il faut que ma classe datamodule soit hermétique au dataset  coisi et au modèle de segmentation choisi et éventuellement à la loss (choisie si tant est qu'elle marche )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c6d1c3e2-f354-4311-85e5-b6cb34f1d316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#%reload_ext autoreload\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import gc\n",
    "import albumentations as album\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "\n",
    "## from src\n",
    "from datas.components.dataset import PleiadeDataset\n",
    "from models.components.segmentation_models import DeepLabv3Module\n",
    "from models.segmentation_module import SegmentationModule\n",
    "from datas.datamodule import DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e85394b9-960e-4ad7-8d31-9ad5abae65db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install mlflow\n",
    "import mlflow\n",
    "\n",
    "run_name = \"baba\"\n",
    "remote_server_uri = \"https://projet-slums-detection-2439.user.lab.sspcloud.fr\"\n",
    "experiment_name = \"segmentation\"\n",
    "\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "\n",
    "## Création Dataset\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "dir_data = \"../splitted_data\"\n",
    "list_path_labels =  np.sort([dir_data + \"/labels/\" + name for name in os.listdir(dir_data+\"/labels\")])# os.wlk dans d'autres cas sous des sous arbres de S2Looking\n",
    "list_path_images =  np.sort([dir_data + \"/images/\" + name for name in os.listdir(dir_data+\"/images\")])\n",
    "\n",
    "\n",
    "image_size = (250,250)\n",
    "transforms_augmentation = album.Compose(\n",
    "        [\n",
    "            album.Resize(300, 300, always_apply=True),\n",
    "            album.RandomResizedCrop(\n",
    "                *image_size, scale=(0.7, 1.0), ratio=(0.7, 1)\n",
    "            ),\n",
    "            album.HorizontalFlip(),\n",
    "            album.VerticalFlip(),\n",
    "            album.Normalize(),\n",
    "            ToTensorV2(),\n",
    "       ]\n",
    "    )\n",
    "\n",
    "transforms_preprocessing = album.Compose(\n",
    "        [\n",
    "            album.Resize(*image_size, always_apply=True),\n",
    "            album.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    ")\n",
    "\n",
    "mono_image_dataset = PleiadeDataset(list_path_images,list_path_labels)\n",
    "\n",
    "\n",
    "## Instanciation modèle et paramètres d'entraînement\n",
    "\n",
    "optimizer = torch.optim.SGD\n",
    "optimizer_params = {\"lr\": 0.0001, \"momentum\": 0.9}\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "scheduler_params = {}\n",
    "scheduler_interval = \"epoch\"\n",
    "\n",
    "model = DeepLabv3Module()\n",
    "\n",
    "##Instanciation des datamodule et plmodule\n",
    "\n",
    "\n",
    "data_module = DataModule(\n",
    "    mono_image_dataset= mono_image_dataset,\n",
    "    transforms_augmentation=transforms_augmentation,\n",
    "    transforms_preprocessing=transforms_preprocessing,\n",
    "    num_workers=1, \n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "\n",
    "lightning_module = SegmentationModule(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_params=optimizer_params,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_params=scheduler_params,\n",
    "    scheduler_interval=scheduler_interval,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"validation_loss\", save_top_k=1, save_last=True, mode=\"min\"\n",
    ")\n",
    "\n",
    "checkpoint_callback_2 = ModelCheckpoint(\n",
    "    monitor=\"train_loss\", save_top_k=1, save_last=True, mode=\"min\"\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"validation_loss\", mode=\"min\", patience=3\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "strategy =\"auto\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "    callbacks=[lr_monitor, checkpoint_callback,checkpoint_callback_2, early_stop_callback],\n",
    "    max_epochs=100,\n",
    "    num_sanity_val_steps=2,\n",
    "    strategy=strategy,\n",
    "    log_every_n_steps=2\n",
    "    )\n",
    "    trainer.fit(lightning_module, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757ef55-0d17-4141-8c99-eac1960b9c62",
   "metadata": {},
   "source": [
    "### Pour tester :\n",
    "On peut mettre n'importe quel dataloader compatible là dedans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7bdf5748-d613-4dad-8aef-f9df24378f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(lightning_module,data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a1f7b15b-e8c2-42f1-aad5-b374e8b684a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.listdir('/home/onyxia/work/detection-habitat-spontane/notebooks/lightning_logs/version_24/checkpoints/')\n",
    "lightning_module_checkpoint = lightning_module.load_from_checkpoint(\n",
    "    checkpoint_path=trainer.checkpoint_callback.best_model_path\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_params=optimizer_params,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_params=scheduler_params,\n",
    "    scheduler_interval=scheduler_interval\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c3e27aee-eeef-43b7-896a-af6f3771b1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image, label, dico =  data_module.mono_image_dataset.__getitem__(10000)\n",
    "            \n",
    "satellite_image = SatelliteImage.from_raster(\n",
    "        file_path = dico[\"pathimage\"],\n",
    "        dep = None,\n",
    "        date = None,\n",
    "        n_bands= 3)\n",
    "\n",
    "#satellite_image.array\n",
    "satellite_image.plot([0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88ee46-2bb2-4031-ae82-feaf056955ea",
   "metadata": {},
   "source": [
    "## S2Looking training !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a8e0e-8e3f-412a-b0ff-1b4adc834bda",
   "metadata": {},
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "04ec8dae-414f-4551-bee2-8138815235c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_storage_access()\n",
    "environment = get_environment()\n",
    "root_path = get_root_path()\n",
    "bucket = environment[\"bucket\"]\n",
    "path_s3_s2looking = environment[\"sources\"][\"PAPERS\"][\"S2Looking\"]\n",
    "path_local_s2looking = environment[\"local-path\"][\"PAPERS\"]\n",
    "\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n",
    "\n",
    "fs.download(\n",
    "        rpath=f\"{bucket}/{path_s3_s2looking}\",\n",
    "        lpath=f\"../{path_local_s2looking}\",\n",
    "        recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d8f1dc5c-b4a2-4dba-b669-595b7673c0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(f\"../{path_local_s2looking}/S2Looking.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(f\"../{path_local_s2looking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aceff44-be32-4bc2-a95d-aa0e8de1c2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = 3\n",
    "a\n",
    "\n",
    "os.listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c371e3-b977-4e74-8891-b87ac1d28a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlflow\n",
    "import mlflow\n",
    "\n",
    "run_name = \"s2looking\"\n",
    "remote_server_uri = \"https://projet-slums-detection-2439.user.lab.sspcloud.fr\"\n",
    "experiment_name = \"change_detection\"\n",
    "\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "\n",
    "## Création Dataset\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "dir_data = \"../splitted_data\"\n",
    "list_path_labels =  np.sort([dir_data + \"/labels/\" + name for name in os.listdir(dir_data+\"/labels\")])# os.wlk dans d'autres cas sous des sous arbres de S2Looking\n",
    "list_path_images =  np.sort([dir_data + \"/images/\" + name for name in os.listdir(dir_data+\"/images\")])\n",
    "\n",
    "\n",
    "image_size = (250,250)\n",
    "transforms_augmentation = album.Compose(\n",
    "        [\n",
    "            album.Resize(300, 300, always_apply=True),\n",
    "            album.RandomResizedCrop(\n",
    "                *image_size, scale=(0.7, 1.0), ratio=(0.7, 1)\n",
    "            ),\n",
    "            album.HorizontalFlip(),\n",
    "            album.VerticalFlip(),\n",
    "            album.Normalize(),\n",
    "            ToTensorV2(),\n",
    "       ]\n",
    "    )\n",
    "\n",
    "transforms_preprocessing = album.Compose(\n",
    "        [\n",
    "            album.Resize(*image_size, always_apply=True),\n",
    "            album.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    ")\n",
    "\n",
    "mono_image_dataset = PleiadeDataset(list_path_images,list_path_labels)\n",
    "\n",
    "\n",
    "## Instanciation modèle et paramètres d'entraînement\n",
    "\n",
    "optimizer = torch.optim.SGD\n",
    "optimizer_params = {\"lr\": 0.0001, \"momentum\": 0.9}\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "scheduler_params = {}\n",
    "scheduler_interval = \"epoch\"\n",
    "\n",
    "model = DeepLabv3Module()\n",
    "\n",
    "##Instanciation des datamodule et plmodule\n",
    "\n",
    "\n",
    "data_module = DataModule(\n",
    "    mono_image_dataset= mono_image_dataset,\n",
    "    transforms_augmentation=transforms_augmentation,\n",
    "    transforms_preprocessing=transforms_preprocessing,\n",
    "    num_workers=1, \n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "\n",
    "lightning_module = SegmentationModule(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_params=optimizer_params,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_params=scheduler_params,\n",
    "    scheduler_interval=scheduler_interval,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"validation_loss\", save_top_k=1, save_last=True, mode=\"min\"\n",
    ")\n",
    "\n",
    "checkpoint_callback_2 = ModelCheckpoint(\n",
    "    monitor=\"train_loss\", save_top_k=1, save_last=True, mode=\"min\"\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"validation_loss\", mode=\"min\", patience=3\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "strategy =\"auto\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "    callbacks=[lr_monitor, checkpoint_callback,checkpoint_callback_2, early_stop_callback],\n",
    "    max_epochs=100,\n",
    "    num_sanity_val_steps=2,\n",
    "    strategy=strategy,\n",
    "    log_every_n_steps=2\n",
    "    )\n",
    "    trainer.fit(lightning_module, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a23f9-7465-40b3-8711-47b3907eb29a",
   "metadata": {},
   "source": [
    "Je ne vais pas modifier mais proposer une classe plus générique de Segementation module !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b46b5-5943-4520-b132-83e65ba585e8",
   "metadata": {},
   "source": [
    "#### 1) modification des codes de Tom pour que son train marche quand même !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e935e-c885-4d26-aa38-f47a742604aa",
   "metadata": {},
   "source": [
    "## TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef3f7dc-59e0-4db4-b415-e280a16f8b79",
   "metadata": {},
   "source": [
    "- Trouver des exemples à changements dans Mayotte\n",
    "- istoo black, ddetection de nuages\n",
    "- filtrer les patchs mauvais, avant l'écriture.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
