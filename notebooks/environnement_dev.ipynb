{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e064d8b4-2af2-4263-800f-713875386be0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fonction to Raster\n",
    "Prend en entrée une Satellite Image, un dossier et un nom et la sauve en JP2 dans le dossier considéré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b683696-509c-466e-bdee-73d3aba6e3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install pyarrow -q -q -q \n",
    "! pip install rasterio -q -q -q \n",
    "! pip install geopandas -q -q -q\n",
    "! pip install matplotlib -q -q -q\n",
    "! pip install albumentations -q -q -q\n",
    "! pip install pytorch_lightning -q -q -q\n",
    "!pip install mlflow -q -q -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "524c5b49-9f48-4092-a43a-ad47710a6f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils.satellite_image import SatelliteImage\n",
    "from utils.utils import *\n",
    "from utils.plot_utils import *\n",
    "\n",
    "import yaml\n",
    "import re\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "from PIL import Image as im\n",
    "\n",
    "from datetime import date\n",
    "import re\n",
    "import pyproj\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from utils.labeler import RILLabeler\n",
    "from utils.filter import is_too_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45654cf2-d2ef-4ae5-bf12-5a008ff640c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_path = get_root_path()\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27d90c35-321b-44d0-a9ea-a0b8084ade17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_storage_access()\n",
    "environment = get_environment()\n",
    "\n",
    "root_path = get_root_path()\n",
    "bucket = environment[\"bucket\"]\n",
    "path_s3_cayenne_data = environment[\"sources\"][\"PLEIADES\"][2022][\"guyane\"]\n",
    "path_local_cayenne_data = os.path.join(root_path, environment[\"local-path\"][\"PLEIADES\"][2022][\"guyane\"])\n",
    "\n",
    "path_s3_pleiades_data_2022_martinique = environment[\"sources\"][\"PLEIADES\"][2022][\"martinique\"]\n",
    "path_local_pleiades_data_2022_martinique = os.path.join(root_path,environment[\"local-path\"][\"PLEIADES\"][2022][\"martinique\"])\n",
    "\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c52f8d-716b-4dbb-ace7-2b440d2bd6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.download(\n",
    "        rpath=f\"{bucket}/{path_s3_cayenne_data}\",\n",
    "        lpath=f\"{path_local_cayenne_data}\",\n",
    "        recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c92228ba-5dd3-4755-83e5-afa24a5b7e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs.download(\n",
    "        rpath=f\"{bucket}/{path_s3_pleiades_data_2022_martinique}\",\n",
    "        lpath=f\"{path_local_pleiades_data_2022_martinique}\",\n",
    "        recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4c183-2d06-4364-89da-94633ca0757a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_raster(satellite_image,directory_name,file_name):\n",
    "    \"\"\"\n",
    "    save a SatelliteImage Object into a raster file (.tif)\n",
    "\n",
    "    Args:\n",
    "        satellite_image: a SatelliteImage object representing the input image to be saved as a raster file.\n",
    "        directory_name: a string representing the name of the directory where the output file should be saved.\n",
    "        file_name: a string representing the name of the output file.\n",
    "    \"\"\"\n",
    "\n",
    "    data = satellite_image.array\n",
    "    crs  = satellite_image.crs\n",
    "    transform = satellite_image.transform\n",
    "    n_bands = satellite_image.n_bands\n",
    "\n",
    "    metadata = {\n",
    "        'dtype': data.dtype,\n",
    "        'count': n_bands,\n",
    "        'width': data.shape[2],\n",
    "        'height': data.shape[1],\n",
    "        'crs': crs,\n",
    "        'transform': transform\n",
    "    }\n",
    "    \n",
    "    #print(os.path.exists(directory_name))\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "\n",
    "    # Save the array as a raster file in jp2 format\n",
    "    with rasterio.open(directory_name + \"/\" + file_name, 'w', **metadata) as dst:\n",
    "        dst.write(data, indexes = np.arange(n_bands)+1)\n",
    "\n",
    "\n",
    "def write_splitted_images_masks(file_path,output_directory_name,labeler,tile_size,n_bands, dep):\n",
    "    \n",
    "    \"\"\"\n",
    "    write the couple images mask into a specific folder\n",
    "\n",
    "    Args:\n",
    "        file_path: a string representing the path to the directory containing the input image files.\n",
    "        output_directory_name: a string representing the name of the output directory where the split images and masks should be saved.\n",
    "        labeler: a Labeler object representing the labeler used to create segmentation labels.\n",
    "        tile_size: an integer representing the size of the tiles to split the input image into.\n",
    "        n_bands: an integer representing the number of bands in the input image.\n",
    "        dep: a string representing the department of the input image, or None if not applicable.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_images_path  = output_directory_name + \"/images\"\n",
    "    output_masks_path  = output_directory_name + \"/labels\"\n",
    "    \n",
    "    if not os.path.exists(output_masks_path):\n",
    "        os.makedirs(output_masks_path)\n",
    "        \n",
    "    list_name = os.listdir(file_path)\n",
    "    list_path = [file_path + \"/\" + name for name in list_name]\n",
    "    \n",
    "    for path, file_name in zip(list_path,tqdm(list_name)): # tqdm ici \n",
    "\n",
    "        big_satellite_image = SatelliteImage.from_raster(\n",
    "            file_path = path,\n",
    "            dep = None,\n",
    "            date = None,\n",
    "            n_bands= 3\n",
    "        )\n",
    "\n",
    "        list_satellite_image = big_satellite_image.split(tile_size)\n",
    "        list_satellite_image = [im for im in list_satellite_image if not is_too_black(im)]\n",
    "        # mettre le filtre is too black ici !!!\n",
    "        for i, satellite_image in enumerate(list_satellite_image):\n",
    "                \n",
    "                mask = labeler.create_segmentation_label(satellite_image) \n",
    "                file_name_i = file_name.split(\".\")[0]+\"_\"+str(i)\n",
    "                if(np.sum(mask) == 0): # je dégage les masques vides j'écris pasd\n",
    "                    continue\n",
    "                to_raster(satellite_image,output_images_path,file_name_i + \".tif\")\n",
    "                np.save(output_masks_path+\"/\"+file_name_i+\".npy\",mask) # save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b673b6-83d8-4a97-9c25-9af4458d077c",
   "metadata": {},
   "source": [
    "### Test sur une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcba4f9-9ffb-49c6-91b7-4bf83514ad67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "satellite_image = SatelliteImage.from_raster(\n",
    "        file_path = f\"{path_local_cayenne_data}\"+ \"/ORT_2022072050325085_0352_0545_U22N_16Bits.jp2\",\n",
    "        dep = None,\n",
    "        date = None,\n",
    "        n_bands= 4)\n",
    "\n",
    "print(satellite_image.array.shape)\n",
    "i = 2\n",
    "directory_name = \"../splitted_data\"\n",
    "file_name = \"ORT_2022072050325085_0352_0545_U22N_16Bits\"+\"_\"+str(i)+\".tif\"\n",
    "\n",
    "to_raster(satellite_image,directory_name,file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8440798-f11c-4261-a8e0-ad2c17cbaf58",
   "metadata": {},
   "source": [
    "## Test sur l'ensemble des images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e4631-0148-411f-a1b6-8b80f013458b",
   "metadata": {},
   "source": [
    "- je prends un répertoire en entrée Par exemple Guyane et je lis je split et réécris les images en taille 250\n",
    "- compter le nombre d'images à traiter et le nombre d'images à l'arrivée.\n",
    "- Si plusieurs années dispo généraliser le labeller "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c3a11-05cd-4146-9b11-d6510497d958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840269a-d846-4962-a4d4-79e8eb0321c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# params \n",
    "file_path = f\"{path_local_pleiades_data_2022_martinique}\"\n",
    "tile_size = 250\n",
    "n_bands = 3\n",
    "dep =\"973\"\n",
    "filename = os.listdir(file_path)[0]\n",
    "date = datetime.strptime(re.search(r'ORT_(\\d{8})', filename).group(1), '%Y%m%d') \n",
    "labeler = RILLabeler(date, dep = dep, buffer_size = 10) \n",
    "output_directory_name = \"../splitted_data\"\n",
    "\n",
    "write_splitted_images_masks(file_path,output_directory_name,labeler,tile_size,n_bands,dep)\n",
    "\n",
    "# 1 min pour 250 -> 4min pour 1000, ça se tente un peu lionguet mais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12338605-a045-40f0-9261-6988618b22b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(os.listdir(output_directory_name+\"/labels\"))\n",
    "len(os.listdir(output_directory_name+\"/images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea14795-2b15-405e-9996-c6b41776baae",
   "metadata": {},
   "source": [
    "- a priori si je connais le file path : je connais la date et je connais le labeller => créer labeller en amont ?\n",
    "- On crée un labeller par date et par territoire concerné \n",
    "- On créé les masques et on les sauvegarde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a045d-bfa4-498e-b36e-edf16850fc97",
   "metadata": {
    "tags": []
   },
   "source": [
    " ### Train un modèle de segmentation Réadaptation de la classe DeeplaV3module pour la rendre agnostique  au dataset etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6d1c3e2-f354-4311-85e5-b6cb34f1d316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#%reload_ext autoreload\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import utils.utils\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import gc\n",
    "import albumentations as album\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "\n",
    "## from src\n",
    "from datas.components.dataset import PleiadeDataset, ChangeDetectionS2LookingDataset\n",
    "from models.components.segmentation_models import DeepLabv3Module\n",
    "from models.segmentation_module import SegmentationModule\n",
    "from datas.datamodule import DataModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead3340-46dc-46c5-ac2b-4a5f65e76d73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_storage_access()\n",
    "#%env AWS_ACCESS_KEY_ID=projet-slums-sa\n",
    "#%env AWS_SECRET_ACCESS_KEY=hB2N6hCmp7JoFA6WHKT022WJ9lOc1oOr # chercher ça dans secret ? normalement le update storage access suffit\n",
    "#%env AWS_S3_ENDPOINT=minio.lab.sspcloud.fr\n",
    "%env MLFLOW_S3_ENDPOINT_URL=https://minio.lab.sspcloud.fr\n",
    "# à préciser en +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48d4386-4dab-4586-9280-f5ced1f491f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "satellite_image = SatelliteImage.from_raster(\n",
    "        file_path = \"../data/PLEIADES/2022/MARTINIQUE/ORT_2022_0691_1638_U20N_8Bits.jp2\",\n",
    "    #\"../data/PLEIADES/2020/MAYOTTE/ORT_2020052526670967_0524_8590_U38S_8Bits.jp2\", # 255 couleurs..\n",
    "        dep = None,\n",
    "        date = None,\n",
    "        n_bands= 3)\n",
    "satellite_image.plot([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24547eb-a00e-43b5-a986-ae47d8c83273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## Création Dataset\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "dir_data = \"../splitted_data\"\n",
    "list_path_labels =  np.sort([dir_data + \"/labels/\" + name for name in os.listdir(dir_data+\"/labels\")])# os.wlk dans d'autres cas sous des sous arbres de S2Looking\n",
    "list_path_images =  np.sort([dir_data + \"/images/\" + name for name in os.listdir(dir_data+\"/images\")])\n",
    "dataset = PleiadeDataset(list_path_images,list_path_labels)\n",
    "\n",
    "# liste d'images test à tester \n",
    "satellite_image = SatelliteImage.from_raster(\n",
    "        file_path =  \"../data/PLEIADES/2020/MAYOTTE/ORT_2020052526670967_0524_8590_U38S_8Bits.jp2\",\n",
    "    # \"../data/PLEIADES/2022/MARTINIQUE/ORT_2022_0691_1638_U20N_8Bits.jp2\",\n",
    "        dep = None,\n",
    "        date = None,\n",
    "        n_bands= 3) # ../data/PLEIADES/2020/MAYOTTE/ORT_2020052526670967_0524_8590_U38S_8Bits.jp2 fonctions d'affichage de Raya\n",
    "\n",
    "list_test = satellite_image.split(250)\n",
    "directory_image_name = \"../test_data/images/\"\n",
    "\n",
    "for i,simg in enumerate(list_test):\n",
    "    file_name = simg.filename.split(\".\")[0] +\"_\"+str(i)+\".tif\"\n",
    "    to_raster(simg,directory_image_name,file_name)\n",
    "\n",
    "list_path_images_test = np.sort([directory_image_name + filename for filename in os.listdir(directory_image_name)])\n",
    "list_path_labels_test =   np.sort(list_path_labels[:len(list_path_images_test)])# pas propre je metsd une liste de labels de même taille inutilisés\n",
    "\n",
    "dataset_test = PleiadeDataset(list_path_images_test,list_path_labels_test) \n",
    "\n",
    "# à changer avec des images bien spécifiques et une fonction préparer test\n",
    "# faire un mini batch qui ne contient que les patchs d'uune image d'intérêt créer les fichiers iages en local et les utiliser pour reconstituer une full image !\n",
    "# print(list_path_images_test)\n",
    "\n",
    "## Transforms à mettre dans le data module\n",
    "image_size = (250,250)\n",
    "transforms_augmentation = album.Compose(\n",
    "        [\n",
    "            album.Resize(300, 300, always_apply=True),\n",
    "            album.RandomResizedCrop(\n",
    "                *image_size, scale=(0.7, 1.0), ratio=(0.7, 1)\n",
    "            ),\n",
    "            album.HorizontalFlip(),\n",
    "            album.VerticalFlip(),\n",
    "            album.Normalize(),\n",
    "            ToTensorV2(),\n",
    "       ]\n",
    "    )\n",
    "\n",
    "transforms_preprocessing = album.Compose(\n",
    "        [\n",
    "            album.Resize(*image_size, always_apply=True),\n",
    "            album.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "## Instanciation modèle et paramètres d'entraînement\n",
    "\n",
    "optimizer = torch.optim.SGD\n",
    "optimizer_params = {\"lr\": 0.0001, \"momentum\": 0.9}\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "scheduler_params = {}\n",
    "scheduler_interval = \"epoch\"\n",
    "\n",
    "model = DeepLabv3Module()\n",
    "\n",
    "\n",
    "\n",
    "##Instanciation des datamodule et plmodule\n",
    "\n",
    "\n",
    "data_module = DataModule(\n",
    "    dataset= dataset,\n",
    "    transforms_augmentation=transforms_augmentation,\n",
    "    transforms_preprocessing=transforms_preprocessing,\n",
    "    num_workers=1, \n",
    "    batch_size=9,\n",
    "    dataset_test = dataset_test\n",
    ")\n",
    "\n",
    "\n",
    "lightning_module = SegmentationModule(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_params=optimizer_params,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_params=scheduler_params,\n",
    "    scheduler_interval=scheduler_interval,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"validation_IOU\", save_top_k=1, save_last=True, mode=\"max\"\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"validation_loss\", mode=\"min\", patience=3\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "strategy =\"auto\"\n",
    "list_callbacks = [lr_monitor, checkpoint_callback, early_stop_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf94a915-cd4a-4819-88ad-45f690e4153f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install mlflow\n",
    "import mlflow\n",
    "mlflow.end_run()\n",
    "\n",
    "run_name = \"modele deeplabV37\"\n",
    "remote_server_uri = \"https://projet-slums-detection-386760.user.lab.sspcloud.fr\"\n",
    "experiment_name = \"segmentation\"\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "    callbacks= list_callbacks,\n",
    "    max_epochs=100,\n",
    "    num_sanity_val_steps=2,\n",
    "    strategy=strategy,\n",
    "    log_every_n_steps=2\n",
    "    )\n",
    "    trainer.fit(lightning_module, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd1b8d-f7d7-4671-ad65-0a6ea8be0244",
   "metadata": {},
   "source": [
    "## Test du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c32c8b68-e33c-450a-a448-987769cc786f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trainer.checkpoint_callback.best_model_path\n",
    "import mlflow\n",
    "mlflow.end_run()\n",
    "\n",
    "run_name = \"modele deeplabV35\"\n",
    "remote_server_uri = \"https://projet-slums-detection-386760.user.lab.sspcloud.fr\"\n",
    "experiment_name = \"segmentation\"\n",
    "\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "output_ligthning = '~/work/detection-habitat-spontane/notebooks/lightning_logs/'\n",
    "\n",
    "with mlflow.start_run(run_id=\"f0ae3db014404b98863792fbdb48a289\"):\n",
    "    model = DeepLabv3Module()\n",
    "    \n",
    "    lightning_module_checkpoint = lightning_module.load_from_checkpoint(\n",
    "    checkpoint_path=trainer.checkpoint_callback.best_model_path,\n",
    "    #checkpoint_path=output_ligthning+'version_O/checkpoints/last.ckpt',\n",
    "    model= model,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_params=optimizer_params,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_params=scheduler_params,\n",
    "    scheduler_interval=scheduler_interval\n",
    "                                         )\n",
    "    artifact_path = \"modele_segmentation_deeplabv3\"\n",
    "    mlflow.pytorch.log_model(lightning_module_checkpoint.model, artifact_path)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "    callbacks= list_callbacks,\n",
    "    max_epochs=50,\n",
    "    num_sanity_val_steps=2,\n",
    "    strategy=strategy,\n",
    "    log_every_n_steps=2\n",
    "    )\n",
    "    trainer.test(lightning_module_checkpoint, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceee4ee-fd85-410b-8faf-c847f49fcd68",
   "metadata": {},
   "source": [
    "# faire une fonction !!\n",
    "- Ici j'évalue un batch à la mano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2d75f-0f8c-4795-8a69-3ba0d7440b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_quick(datasetparam,model,idx):\n",
    "    imagesat = SatelliteImage.from_raster(datasetparam.list_paths_images[idx],\"976\",n_bands = 3) \n",
    "\n",
    "    model.eval()\n",
    "    model = model.to(\"cuda\")\n",
    "    #image, mask, dic = dataset_test[idx]\n",
    "    image, mask, dic = datasetparam[idx]\n",
    "\n",
    "    # mask réel\n",
    "    plt.imshow(mask, cmap='binary', interpolation='none')\n",
    "    plt.colorbar(ticks=[0, 1])\n",
    "    plt.show()\n",
    "\n",
    "    # image\n",
    "    imagesat.plot([0,1,2])\n",
    "\n",
    "    # model\n",
    "    output = model(image.unsqueeze(0).to(\"cuda\"))\n",
    "    print(output.shape)\n",
    "    mask_model = np.array(torch.argmax(output,axis= 1).squeeze(0).to(\"cpu\"))\n",
    "    print(np.sum(mask_model))\n",
    "    # mask model\n",
    "    plt.imshow(mask_model, cmap='binary', interpolation='none')\n",
    "    plt.colorbar(ticks=[0, 1])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaab72a-0654-47dc-a623-77e6a9abe834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd93db-61ff-426f-a1db-8e51f287c9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model = lightning_module_checkpoint.model\n",
    "#evaluate_quick(dataset,model,23)\n",
    "evaluate_quick(dataset,model,70)\n",
    "evaluate_quick(dataset_test,model,49)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9202a80-55fa-4b10-91fb-37cfceab8f0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "- marrant de voir comment la normalisation detecte les logements..sérendipité\n",
    "- qgis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd1904-5517-4ab8-8059-2777c3e70227",
   "metadata": {},
   "source": [
    "## PEtite enquête pour savoir pourquoi les résultats sont éclatés sur l'exmple de MAyotte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd4a8f4-33c5-4968-bd68-7eab9cde38a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 2\n",
    "\n",
    "for idx in range(64):\n",
    "    imagesat = SatelliteImage.from_raster(dataset_test.list_paths_images[idx],\"976\",n_bands = 3) \n",
    "    print(torch.max(dataset_test[idx][0]))\n",
    "    np.max(imagesat.array)\n",
    "    \n",
    "for idx in range(64):\n",
    "    imagesat = SatelliteImage.from_raster(dataset.list_paths_images[idx],\"976\",n_bands = 3) \n",
    "    print(torch.max(dataset[idx][0]))\n",
    "    np.max(imagesat.array)\n",
    "np.max(satellite_image.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8f78b2-7b5d-4ce7-8a0b-04bc429e3a82",
   "metadata": {},
   "source": [
    "Il y a déjà une normalisation entre 0 et 255 appliqué&e sur mayotte ça peut forcément pas marcher.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757ef55-0d17-4141-8c99-eac1960b9c62",
   "metadata": {},
   "source": [
    "### Test du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165ff6d-969d-4343-9fc2-53b2891c3071",
   "metadata": {},
   "source": [
    "TO DO :\n",
    "- les images Guyane sont en 16 bits et MAyotte et martinique etc.. en 8 normal que ça deconne\n",
    "- faire en sorte de calculer plusieurs grosse images sur le .test et trouver une autre image que mayotte pour le moment qui est en 255 couleurs... != du reste\n",
    "- mettre une oimage de la validation en jeu\n",
    "- mettre le calcul d'image dans la validation aussi ?\n",
    "- mettre dans data set test une image du jeu de validatio à minima et une image de jeu externe etc..\n",
    "- dégager aussi les RIL vides ? Oui\n",
    "- labelstudio, segment anything model\n",
    "- bien construire un beau jeu de test avec cet outil  label studio, labellisation à la main , pour evaluation pertinente !!\n",
    "- mettre le [0,1,2] par défautdans les plots\n",
    "- se servir du if batch idx == 10 recharger tout les fichiers des batchs précédents et en faire une satellite data, stocker également ce qui fera une seule image et donc une seule labelled satellite image ..\n",
    "- dans le filename des images splittée changer avec les bonnes coordonnées dans lenom (trouvable dans la bounding box..)\n",
    "- faire une fonction générer dataset test qui servira pour tous les tests\n",
    "- test de lancement via invit de comande train\n",
    "- généraliser la création de liste de file path selon le dataset souhaité\n",
    "- créer un yaml de config et le logger dans mlflow\n",
    "- contrîole sur le modèle qui est loggé dans ml flow ?\n",
    "- resoudre le bug sur l'ambiguité du nombre d'elemeents dans le batch\n",
    "- workshop fevrier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc074164-878d-4598-8cea-df6c4bd5ed54",
   "metadata": {
    "tags": []
   },
   "source": [
    "Reunion section\n",
    "- 13 travaux\n",
    "- Production de masques : Juin Juillet,\n",
    "    - Esane normal + Branches\n",
    "    - demographie  # RDV Nathanael + soutien code\n",
    "    - maj EAP (Optionnel)\n",
    "    - IPI ICA\n",
    "    - Antipol, tab multi\n",
    "    \n",
    "rtauargus prez , veux-tu présenter ? nathanael ?\n",
    "fideli ..\n",
    "pour rtauargus mix des différentes présentations déjà faites :\n",
    "que veux-on partager, pas NTTIS\n",
    "différentes prez du worksho en Septembre dernier exemples bien senti\n",
    "\n",
    "Présentation \"paillettes\" -> d'où vient la complexité des données ? décrire avec le graph\n",
    "tau argus outil de référence, différnets types de complexité , une partie résolu liens tableaux, partie non résolue, partie analyse de la demande, + méta données non automatisées\n",
    "-> rtauargus\n",
    "-> \n",
    "-> création liste de tables c'est sympa ça demande une généralisation, une métadonnées nickel permettrait d'automatiser cette analyse\n",
    "-> insee.fr exemple, overlezf, reprise présentation\n",
    "\n",
    "- census bureau litterature reunion Julien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88ee46-2bb2-4031-ae82-feaf056955ea",
   "metadata": {},
   "source": [
    "## S2Looking training !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a8e0e-8e3f-412a-b0ff-1b4adc834bda",
   "metadata": {},
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ec8dae-414f-4551-bee2-8138815235c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_storage_access()\n",
    "environment = get_environment()\n",
    "root_path = get_root_path()\n",
    "bucket = environment[\"bucket\"]\n",
    "path_s3_s2looking = environment[\"sources\"][\"PAPERS\"][\"S2Looking\"]\n",
    "path_local_s2looking = environment[\"local-path\"][\"PAPERS\"]\n",
    "\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n",
    "\n",
    "fs.download(\n",
    "        rpath=f\"{bucket}/{path_s3_s2looking}\",\n",
    "        lpath=f\"../{path_local_s2looking}\",\n",
    "        recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1dc5c-b4a2-4dba-b669-595b7673c0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(f\"../{path_local_s2looking}/S2Looking.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(f\"../{path_local_s2looking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c371e3-b977-4e74-8891-b87ac1d28a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install mlflow\n",
    "import mlflow\n",
    "\n",
    "run_name = \"s2looking\" # config\n",
    "remote_server_uri = \"https://projet-slums-detection-2439.user.lab.sspcloud.fr\"\n",
    "experiment_name = \"segmentation\" # config\n",
    "\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "# mlflow.pytorch.autolog() # logger la config\n",
    "\n",
    "\n",
    "## Création Dataset\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "## En faire une fonction ? : Idée faire une classe de préparation des données pour chaque data set chargé qui in fine sortirait une list path ?\n",
    "\n",
    "### config, appeler une fionction de création de dataset ?\n",
    "dir_data = \"../data/paper_dataset/S2Looking/\"\n",
    "img1_train = [dir_data + \"train/Image1/\"+name for name in os.listdir(dir_data + \"/train/Image1\")]\n",
    "img1_val = [dir_data + \"train/Image1/\"+name for name in os.listdir(dir_data + \"/train/Image1\")]\n",
    "\n",
    "img1_train = [dir_data + \"train/Image1/\"+name for name in os.listdir(dir_data + \"/train/Image1\")]\n",
    "img1_val = [dir_data + \"val/Image1/\"+name for name in os.listdir(dir_data + \"/val/Image1\")]\n",
    "img1_test = [dir_data + \"test/Image1/\"+name for name in os.listdir(dir_data + \"/test/Image1\")]\n",
    "\n",
    "img2_train = [dir_data + \"train/Image2/\"+name for name in os.listdir(dir_data + \"/train/Image2\")]\n",
    "img2_val = [dir_data + \"val/Image2/\"+name for name in os.listdir(dir_data + \"/val/Image2\")]\n",
    "img2_test = [dir_data + \"test/Image2/\"+name for name in os.listdir(dir_data + \"/test/Image2\")]\n",
    "\n",
    "label_train = [dir_data + \"train/label/\"+name for name in os.listdir(dir_data + \"/train/label\")]\n",
    "label_val = [dir_data + \"val/label/\"+name for name in os.listdir(dir_data + \"/val/label\")]\n",
    "label_test = [dir_data + \"test/label/\"+name for name in os.listdir(dir_data + \"/test/label\")]\n",
    "\n",
    "img1_path = np.concatenate([np.sort(img1_train),np.sort(img1_val),np.sort(img1_test)])\n",
    "img2_path = np.concatenate([np.sort(img2_train),np.sort(img2_val),np.sort(img2_test)])\n",
    "label_path = np.concatenate([np.sort(label_train),np.sort(label_val),np.sort(label_test)])\n",
    "\n",
    "mono_image_dataset = ChangeDetectionS2LookingDataset(img1_path,img2_path,label_path)\n",
    "\n",
    "# transforms incorporé dans les dataset a posteriori\n",
    "image_size = (256,256) # cf la classe dataset\n",
    "transforms_augmentation = album.Compose(\n",
    "        [\n",
    "            album.Resize(300, 300, always_apply=True),\n",
    "            album.RandomResizedCrop(\n",
    "                *image_size, scale=(0.7, 1.0), ratio=(0.7, 1)\n",
    "            ),\n",
    "            album.HorizontalFlip(),\n",
    "            album.VerticalFlip(),\n",
    "            album.Normalize(),\n",
    "            ToTensorV2(),\n",
    "       ]\n",
    "    )\n",
    "\n",
    "transforms_preprocessing = album.Compose(\n",
    "        [\n",
    "            album.Resize(*image_size, always_apply=True),\n",
    "            album.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    ")\n",
    "\n",
    "\n",
    "## Instanciation modèle et paramètres d'entraînement\n",
    "\n",
    "optimizer = torch.optim.SGD\n",
    "optimizer_params = {\"lr\": 0.0001, \"momentum\": 0.9}\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "scheduler_params = {}\n",
    "scheduler_interval = \"epoch\"\n",
    "\n",
    "model = DeepLabv3Module(nchannel = 6) # viens du data set qui concatene 2 images à 3 channels\n",
    "\n",
    "##Instanciation des datamodule et plmodule\n",
    "\n",
    "data_module = DataModule(\n",
    "    mono_image_dataset= mono_image_dataset,\n",
    "    transforms_augmentation=transforms_augmentation,\n",
    "    transforms_preprocessing=transforms_preprocessing,\n",
    "    num_workers=1, \n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "\n",
    "lightning_module = SegmentationModule(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_params=optimizer_params,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_params=scheduler_params,\n",
    "    scheduler_interval=scheduler_interval,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"validation_loss\", save_top_k=1, save_last=True, mode=\"min\"\n",
    ")\n",
    "\n",
    "checkpoint_callback_2 = ModelCheckpoint(\n",
    "    monitor=\"train_loss\", save_top_k=1, save_last=True, mode=\"min\"\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"validation_loss\", mode=\"min\", patience=3\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "strategy =\"auto\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "    callbacks=[lr_monitor, checkpoint_callback,checkpoint_callback_2, early_stop_callback],\n",
    "    max_epochs=100,\n",
    "    num_sanity_val_steps=2,\n",
    "    strategy=strategy,\n",
    "    log_every_n_steps=2\n",
    "    )\n",
    "    trainer.fit(lightning_module, datamodule=data_module)\n",
    "    \n",
    "    lightning_module_checkpoint = lightning_module.load_from_checkpoint(\n",
    "    checkpoint_path=trainer.checkpoint_callback.best_model_path\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_params=optimizer_params,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_params=scheduler_params,\n",
    "    scheduler_interval=scheduler_interval\n",
    "                                     )\n",
    "    artifact_path = \"models/modele_change_detection_deeplabv3_on_s2_looking\"\n",
    "    mlflow.pytorch.log_model(lightning_module_checkpoint.model, artifact_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef23363-3a3c-4b83-8e09-303fce3b4647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
